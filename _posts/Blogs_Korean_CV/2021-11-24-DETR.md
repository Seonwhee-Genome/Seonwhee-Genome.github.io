---
title: "DETR"
tags: [Vision]
categories:
  - Blogs_Korean_CV
date: 2021-11-24
comments: true
use_math: true
---

# 1 DETR 코드 실행

## (1) COCO Dataset

소스코드 파일(수정해서 customize를 한다면, 자기 깃헙 계정으로 Fork를 한다음에 clone 하는 것이 좋다.)

```bash
#git clone https://github.com/facebookresearch/detr.git
git clone https://github.com/Seonwhee-Genome/detr.git
```

Anaconda 가상환경 만들기

```bash
conda create -n detr python=3.7
source activate detr
```

<aside>
💡 Official Github 안내와는 다르게 cython부터 설치를 해야 pytorch downgrade가 되지 않으며
클라우드 서버 Host OS에는 CUDA 10.1이 설치되어 있기 때문에 cudatoolkit은 10.1 이하 버전만이 설치 가능하다. 따라서 pytorch 역시 CUDA 10.1에서 지원되는 최신버전인 1.7로 설치한다.

</aside>

```bash
conda install cython scipy
conda install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=10.1 -c pytorch
```

COCO 데이터셋

```bash
pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'
mkdir COCO
cd COCO
wget http://images.cocodataset.org/zips/train2017.zip
wget http://images.cocodataset.org/zips/val2017.zip
wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip
unzip annotations_trainval2017.zip
unzip val2017.zip
unzip train2017.zip
rm *.zip
```

## (2) Custom Dataset

### 1) 데이터셋 형식 변환

방법 1: COCO dataset 기준으로 소스코드가 작성되어 있으므로, 가지고 있는 데이터의 YOLO annotation을 COCO 형식으로 바꾼다.

[yolo2coco / yolo to coco / yolo format to coco format / YOLO annotation을 COCO 데이터 annotation으로 바꾸기](https://kangjik94.tistory.com/40)

방법 2: YOLO 형식에서 학습을 할 수 있도록 소스코드를 변형한다.

빠르고 쉬운 것은 역시 방법 1이 될 것이다. 따라서 YOLO 방식으로 Annotation 된 custom 데이터들을 위의 코드를 통해서 COCO 형식으로 바꿔주었다.

### 2) num_classes 수정

또 한가지 해줘야 할 것은 Classification을 하기 위해서 class index를 custom 데이터셋 기준으로 맞춰주는 것이다.

[detr/detr.py at main · facebookresearch/detr](https://github.com/facebookresearch/detr/blob/main/models/detr.py)

```python
def build(args):
    # the `num_classes` naming here is somewhat misleading.
    # it indeed corresponds to `max_obj_id + 1`, where max_obj_id
    # is the maximum id for a class in your dataset. For example,
    # COCO has a max_obj_id of 90, so we pass `num_classes` to be 91.
    # As another example, for a dataset that has a single class with id 1,
    # you should pass `num_classes` to be 2 (max_obj_id + 1).
    # For more details on this, check the following discussion
    # https://github.com/facebookresearch/detr/issues/108#issuecomment-650269223
    num_classes = 20 if args.dataset_file != 'coco' else 91    
    if args.dataset_file == "coco_panoptic":
        # for panoptic, we just add a num_classes that is large enough to hold
        # max_obj_id + 1, but the exact value doesn't really matter
        num_classes = 250
    device = torch.device(args.device)

    backbone = build_backbone(args)

    transformer = build_transformer(args)

    model = DETR(
        backbone,
        transformer,
        num_classes=num_classes,
        num_queries=args.num_queries,
        aux_loss=args.aux_loss,
    )
```

위에 코드를 보면 args의 dataset_file 인자가 `'coco'`가 아니라면 `num_classes`를 20으로 주고, `'coco'`인 경우 91로 설정되어 있다. `num_classes`는 실제 클래스의 갯수가 아니라 COCO dataset의 클래스 id 중 가장 큰 값에 1을 더한 값이다.(No object도 예측해야 하므로)

custom 데이터의 Annotation를 확인해 본 결과 가장 큰 Class id가 106이므로 `num_classes`는 107이 되어야 한다.

```python
def build(args):
    
    #num_classes = 20 if args.dataset_file != 'coco' else 91  
    num_classes = 107  
    
```

따라서 detr.py에서 `num_classes`를 위와 같이 바꿔주거나 `main.py` 스크립트를 실행할 때 옵션으로 `—num_classes 107` 로 주면 된다.

### 3) DETR 학습 실행

```bash
ubuntu@nipa2021-36771:~$ cd detr
ubuntu@nipa2021-36771:~/detr$ source activate detr
(detr) ubuntu@nipa2021-36771:~/detr$ nohup python -m torch.distributed.launch --nproc_per_node=2 --use_env main.py --coco_path /home/ubuntu/LunchBox --output_dir /home/ubuntu/Trained_Models/DETR &
```

Github에 나와 있듯이 클라우드에 있는 GPU 2개를 DistributedDataParallel로 학습 시키고, checkpoint pth파일과 로그 파일을 `output_dir` 옵션을 통해 `/home/ubuntu/Trained_Models/DETR`에 저장하며, 백그라운드로 실행시켜서 stdout을 `nohup.out`에 기록되도록 하였다.

### 4) Pre-trained Model의 Fine-tuning

[https://github.com/facebookresearch/detr](https://github.com/facebookresearch/detr)

깃헙의 README를 보면 알 수 있듯이 COCO2017 데이터셋으로 사전학습시킨 모델을 불러와서 Fine-tuning할 수도 있다.

pth 파일을 다운로드 하는 방법은 pytorch로 하거나

```python
ckpt = torch.hub.load_state_dict_from_url(
    url='https://dl.fbaipublicfiles.com/detr/detr-r101-dc5-a2e86def.pth',
    map_location='cpu',
    check_hash=True)
```

쉘에서 wget을 사용하는 방법 중 자유롭게 선택하면 되고, 이 경우 `torch.load`로 불러온다

```bash
wget https://dl.fbaipublicfiles.com/detr/detr-r101-dc5-a2e86def.pth
```

```python
ckpt = torch.load("detr-r101-dc5-a2e86def.pth", map_location='cpu')
```

pth 파일은 weight 값을 저장한 state_dict이다. 따라서 `main.py`에서는 모델 클래스인 `DETR` class의 객체 `model`을 GPU process에 나눈 `model_without_ddp` 객체에서 `load_state_dict`로 호출하여 가중치를 초기화 시키게 된다.

`main.py`를 수정하기 전 사전 작업으로 위에서 `ckpt`로 불러온 state_dict를 수정해주어야 한다.

pre-trained model은 COCO의 90개 클래스 + 1 = 91개 클래스로 학습시켰기 때문에 그냥 main에서 호출해주면 우리 데이터의 클래스 갯수(107개)에 따라 정의된 모델 객체와 dimension이 불일치하는 문제가 생긴다. 

따라서 classification layer인 `class_embed`를 삭제해준다.

```python
del ckpt["model"]["class_embed.weight"]
del ckpt["model"]["class_embed.bias"]
```

그리고 `ckpt`를 저장한다.

```python
torch.save(ckpt,'detr-r101_no-class-head.pth')
```

이제 `main.py`에서 코드 하나만 수정해준다.

```python
		if args.resume:
        if args.resume.startswith('https'):
            checkpoint = torch.hub.load_state_dict_from_url(
                args.resume, map_location='cpu', check_hash=True)
        else:
            checkpoint = torch.load(args.resume, map_location='cpu')
        #model_without_ddp.load_state_dict(checkpoint['model'])
        model_without_ddp.load_state_dict(checkpoint['model'], strict=False) 
        if not args.eval and 'optimizer' in checkpoint and 'lr_scheduler' in checkpoint and 'epoch' in checkpoint:
            optimizer.load_state_dict(checkpoint['optimizer'])
            lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])
            args.start_epoch = checkpoint['epoch'] + 1
```

주석처리된 부분이 원래 코드이고 그 아래줄이 수정된 코드이다. 우리가 위에서 state_dict의 두 key인 `class_embed.weight`와 `class_embed.bias`를 삭제했기 때문에 `strict=False`로 줌으로써 존재하는 key와 그 value인 가중치값만 초기화 시켜주는 것이다.

최종적으로 Pre-trained model을 불러오고 Fine-tuning을 실행시키기 위해서는 쉘에서 실행할 때 옵션 `—resume detr-r101_no-class-head.pth` 으로 준다.

```bash
nohup python -m torch.distributed.launch --nproc_per_node=2 --use_env main.py --coco_path /home/ubuntu/LunchBox --resume /home/ubuntu/detr/detr-r101_no-class-head.pth --output_dir /home/ubuntu/Trained_Models/DETR &
```

### 5) Tensorboard 사용

```bash
pip install tensorboard
```

일단 Tensorboard를 설치한다.

그리고 텐서보드 tfevents 파일이 저장하기 위한 경로를 따로 설정하자. tfevents 파일은 모형 학습의 목적에 따라 비교하기 편하게 따로 폴더를 만들어서 공동으로 관리하는 것이 좋다. 클라우드 서버에서는 상위 폴더인 `/home/ubuntu`에다가 `Tensorboard_log`라는 폴더를 만들었고 그 하부에 `DETR`이라는 폴더를 만들었으며, DETR 학습 로그는 `/home/ubuntu/Tensorboard_log/DETR`에 계속 저장할 것이다. 그리고 `Tensorboard_log`는 읽기 쓰기 변경 권한을 모두 주었다.

```bash
ubuntu@nipa2021-36771:~$ source activate detr
(detr) ubuntu@nipa2021-36771:~$ tensorboard --logdir=/home/ubuntu/Tensorboard_log/DETR --port 6006 --host=0.0.0.0
```

이미 알고 있겠지만 텐서보드의 실행은 간단하다. 포트(클라우드의 경우 6006)가 열려있는지 확인하고, 텐서보드가 설치된 conda 가상환경이나 도커 컨테이너를 통해서 실행하면 된다. `logdir`옵션을 정확히 입력하면 되고, 텐서보드의 실행 위치는 어디든 관계없다.

# 2 소스코드 이모저모

## (1) transformer 모듈

[detr/transformer.py at main · facebookresearch/detr](https://github.com/facebookresearch/detr/blob/main/models/transformer.py)

```python
"""
DETR Transformer class.

Copy-paste from torch.nn.Transformer with modifications:
    * positional encodings are passed in MHattention
    * extra LN at the end of encoder is removed
    * decoder returns a stack of activations from all decoding layers
"""
```

맨 위의 주석을 보면 PyTorch의 `nn.Transformer`를 몇 가지 변경해서 썼다고 명시하고 있다.

positional encoding을 Multi-head attention으로 전달했고, encoder 뒤에 있는 추가적인 Layer Norm을 제거했으며, Decoder는 모든 decoding layer에서의 모든 Activation들을 쌓아서 리턴해준다.

[torch.nn.modules.transformer - PyTorch 1.10.0 documentation](https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#Transformer.forward)

DETR에서의 `Transformer` class이다.

```python
class Transformer(nn.Module):

    def __init__(self, d_model=512, nhead=8, num_encoder_layers=6,
                 num_decoder_layers=6, dim_feedforward=2048, dropout=0.1,
                 activation="relu", normalize_before=False,
                 return_intermediate_dec=False):
        super().__init__()

        encoder_layer = TransformerEncoderLayer(d_model, nhead, dim_feedforward,
                                                dropout, activation, normalize_before)
        encoder_norm = nn.LayerNorm(d_model) if normalize_before else None
        self.encoder = TransformerEncoder(encoder_layer, num_encoder_layers, encoder_norm)

        decoder_layer = TransformerDecoderLayer(d_model, nhead, dim_feedforward,
                                                dropout, activation, normalize_before)
        decoder_norm = nn.LayerNorm(d_model)
        self.decoder = TransformerDecoder(decoder_layer, num_decoder_layers, decoder_norm,
                                          return_intermediate=return_intermediate_dec)

        self._reset_parameters()

        self.d_model = d_model
        self.nhead = nhead

    def _reset_parameters(self):
        for p in self.parameters():
            if p.dim() > 1:
                nn.init.xavier_uniform_(p)

    def forward(self, src, mask, query_embed, pos_embed):
        # flatten NxCxHxW to HWxNxC
        bs, c, h, w = src.shape
        src = src.flatten(2).permute(2, 0, 1)
        pos_embed = pos_embed.flatten(2).permute(2, 0, 1)
        query_embed = query_embed.unsqueeze(1).repeat(1, bs, 1)
        mask = mask.flatten(1)

        tgt = torch.zeros_like(query_embed)
        memory = self.encoder(src, src_key_padding_mask=mask, pos=pos_embed)
        hs = self.decoder(tgt, memory, memory_key_padding_mask=mask,
                          pos=pos_embed, query_pos=query_embed)
        return hs.transpose(1, 2), memory.permute(1, 2, 0).view(bs, c, h, w)
```

`tgt`는 decoder 자체의 input sequence, `memory`는 encoder의 가장 마지막 layer에서  decoder로 전달된 시퀀스이다.  그리고 `tgt_mask`와 `memeory_mask`는 각 시퀀스에 대한 masking이다.

왼쪽이 `nn.TransformerDecoder`이고 오른쪽이 DETR에서 `TransformerDecoder` class이다.

```python
class TransformerDecoder(Module):
    
    __constants__ = ['norm']

    def __init__(self, decoder_layer, num_layers, norm=None):
        super(TransformerDecoder, self).__init__()
        self.layers = _get_clones(decoder_layer, num_layers)
        self.num_layers = num_layers
        self.norm = norm

		def forward(self, tgt: Tensor,
								memory: Tensor, 
							  tgt_mask: Optional[Tensor] = None,
                memory_mask: Optional[Tensor] = None, 
								tgt_key_padding_mask: Optional[Tensor] = None,
                memory_key_padding_mask: Optional[Tensor] = None) -> Tensor:
        
        output = tgt

        for mod in self.layers:
            output = mod(output, memory, tgt_mask=tgt_mask,
                         memory_mask=memory_mask,
                         tgt_key_padding_mask=tgt_key_padding_mask,
                         memory_key_padding_mask=memory_key_padding_mask)

        if self.norm is not None:
            output = self.norm(output)

        return output
```

```python
class TransformerDecoder(nn.Module):

    def __init__(self, decoder_layer, num_layers, norm=None, return_intermediate=False):
        super().__init__()
        self.layers = _get_clones(decoder_layer, num_layers)
        self.num_layers = num_layers
        self.norm = norm
        self.return_intermediate = return_intermediate

    def forward(self, tgt, memory,
                tgt_mask: Optional[Tensor] = None,
                memory_mask: Optional[Tensor] = None,
                tgt_key_padding_mask: Optional[Tensor] = None,
                memory_key_padding_mask: Optional[Tensor] = None,
                pos: Optional[Tensor] = None,
                query_pos: Optional[Tensor] = None):
        output = tgt

        intermediate = []

        for layer in self.layers:
            output = layer(output, memory, tgt_mask=tgt_mask,
                           memory_mask=memory_mask,
                           tgt_key_padding_mask=tgt_key_padding_mask,
                           memory_key_padding_mask=memory_key_padding_mask,
                           pos=pos, query_pos=query_pos)
            if self.return_intermediate:
                intermediate.append(self.norm(output))

        if self.norm is not None:
            output = self.norm(output)
            if self.return_intermediate:
                intermediate.pop()
                intermediate.append(output)

        if self.return_intermediate:
            return torch.stack(intermediate)

        return output.unsqueeze(0)
```

<aside>
⛔ 논문 3.1의 내용은
1) DETR의 Decoder및 FFN을 통해 도출된 N개의 예측결과와 GT의 일대일 대응(bipartite 매칭)을 Hungarian Algorithm을 통해 찾는 것이고 Hungarian Algorithm을 하기 위해 사용되는 것이 바로 Matching cost $\mathcal{L}_{match}$이다. Matching cost는 loss가 아니다. 
2) 매칭된 pair $\hat{\sigma}$를 가지고 다시 loss $\mathcal{L}_{Hungarian}$를 구해서 DETR의 parameter update를 한다.
내가 헷갈렸던 이유는 $\hat{p}_{\sigma(i)}(c_i)$와 $\mathcal{L}_{box}$같은 Notation이 matching cost를 구할 때도 들어갔고 loss를 구할 때도 들어갔기 때문인데, 별개의 과정이다. 전자는 $\hat{p}_{\sigma(i)}$이고, 후자는 $\hat{p}_{\hat{\sigma}(i)}$이다.

</aside>

## (2) Bipartite Matching


```python
class HungarianMatcher(nn.Module):
    """This class computes an assignment between the targets and the predictions of the network
    For efficiency reasons, the targets don't include the no_object. Because of this, in general,
    there are more predictions than targets. In this case, we do a 1-to-1 matching of the best predictions,
    while the others are un-matched (and thus treated as non-objects).
    """

    def __init__(self, cost_class: float = 1, cost_bbox: float = 1, cost_giou: float = 1):
        """Creates the matcher
        Params:
            cost_class: This is the relative weight of the classification error in the matching cost
            cost_bbox: This is the relative weight of the L1 error of the bounding box coordinates in the matching cost
            cost_giou: This is the relative weight of the giou loss of the bounding box in the matching cost
        """
        super().__init__()
        self.cost_class = cost_class
        self.cost_bbox = cost_bbox
        self.cost_giou = cost_giou
        assert cost_class != 0 or cost_bbox != 0 or cost_giou != 0, "all costs cant be 0"

    @torch.no_grad()
    def forward(self, outputs, targets):
        """ Performs the matching
        Params:
            outputs: This is a dict that contains at least these entries:
                 "pred_logits": Tensor of dim [batch_size, num_queries, num_classes] with the classification logits
                 "pred_boxes": Tensor of dim [batch_size, num_queries, 4] with the predicted box coordinates
            targets: This is a list of targets (len(targets) = batch_size), where each target is a dict containing:
                 "labels": Tensor of dim [num_target_boxes] (where num_target_boxes is the number of ground-truth
                           objects in the target) containing the class labels
                 "boxes": Tensor of dim [num_target_boxes, 4] containing the target box coordinates
        Returns:
            A list of size batch_size, containing tuples of (index_i, index_j) where:
                - index_i is the indices of the selected predictions (in order)
                - index_j is the indices of the corresponding selected targets (in order)
            For each batch element, it holds:
                len(index_i) = len(index_j) = min(num_queries, num_target_boxes)
        """
        bs, num_queries = outputs["pred_logits"].shape[:2]

        # We flatten to compute the cost matrices in a batch
        out_prob = outputs["pred_logits"].flatten(0, 1).softmax(-1)  # [batch_size * num_queries, num_classes]
        out_bbox = outputs["pred_boxes"].flatten(0, 1)  # [batch_size * num_queries, 4]

        # Also concat the target labels and boxes
        tgt_ids = torch.cat([v["labels"] for v in targets])
        tgt_bbox = torch.cat([v["boxes"] for v in targets])

        # Compute the classification cost. Contrary to the loss, we don't use the NLL,
        # but approximate it in 1 - proba[target class].
        # The 1 is a constant that doesn't change the matching, it can be ommitted.
        cost_class = -out_prob[:, tgt_ids]

        # Compute the L1 cost between boxes
        cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1)

        # Compute the giou cost betwen boxes
        cost_giou = -generalized_box_iou(box_cxcywh_to_xyxy(out_bbox), box_cxcywh_to_xyxy(tgt_bbox))

        # Final cost matrix
        C = self.cost_bbox * cost_bbox + self.cost_class * cost_class + self.cost_giou * cost_giou
        C = C.view(bs, num_queries, -1).cpu()  #C를 batch size x num_queries로 reshape

        sizes = [len(v["boxes"]) for v in targets]
        indices = [linear_sum_assignment(c[i]) for i, c in enumerate(C.split(sizes, -1))]
        return [(torch.as_tensor(i, dtype=torch.int64), torch.as_tensor(j, dtype=torch.int64)) for i, j in indices]
```

$\hat{p}_{\sigma(i)}(c_i)$는 논문에서 소개한 대로 class $c_i$의 확률이며 위의 코드에서는 `out_prob[:, tgt_ids]`로 선언되어 있다.

$b_i$는 GT BBox이며 코드에서는 `tgt_bbox`, $\hat{b}_{\sigma(i)}$는 예측된 BBox 중에 $i$번째 GT와 matching되는 BBox이며 코드에서는 `out_bbox`다.

Bounding box의 loss는 $\mathcal{L}_{box}$이고, gIoU와 L1 loss의 선형결합으로 정의했었다.  

$\mathcal{L}_{box}(b_i)$  

$ \mathcal{L}_{box}(b_i,\hat{b}_{\sigma(i)})=\lambda_{iou}\mathcal{L}_{iou}(b_i,\hat{b}_{\sigma(i)})+\lambda_{L1}\left\|{b_i,\hat{b}_{\sigma(i)}}\right\|_1 $  

그리고 전체 Matching cost $\mathcal{L}_{match}$는 다음과 같이 정의 되었다.  

$ \mathcal{L}_{match}(y_i,\hat{y}_{\sigma(i)})=-\mathbb{1}_{\{c_i\neq \varnothing\}}\hat{p}_{\sigma(i)}+\mathbb{1}_{\{c_i\neq \varnothing\}}\mathcal{L}_{box}(b_i,\hat{b}_{\sigma(i)} )$  

우선 $\mathcal{L}_{box}$는 코드 상에서 따로 선언하지 않았다. $\mathcal{L}_{match}$는 코드 상에서는 `C` 로 선언되어 있으며, 

$\lambda_{iou}$가 `self.cost_giou`, $\mathcal{L}_{iou}$가 `cost_giou`, $\lambda_{L1}$이 `self.cost_bbox`, $\left\|{b_i,\hat{b}_{\sigma(i)}}\right\|_1$가 `cost_bbox`에 해당된다.  

특기할 점은 논문상에서 나오지는 않지만 classification에 대한 cost 역시 따로 구해줬는데, 코드의 주석에 나와 있듯이 loss 처럼 Negative Log Likelihood를 사용한게 아니라 $1-\hat{p}_{\sigma(i)}(c_i)$인데 mathcing에서는 1에서 빼주는 것이 큰 의미가 없어서 그냥 $-\hat{p}_{\sigma(i)}(c_i)$로 정의했고 그게 `cost_class`이다. 그리고 classification cost에 대한 가중치를 주기 위해 `self.cost_class`도 선언했다.

Bipartite assignment를 하는 Hungarian Algorithm은 `scipy.optimize`의 `linear_sum_assignment`에서 Cost matrix를 input으로 받아서 수행한다.

[scipy.optimize.linear_sum_assignment - SciPy v0.18.1 Reference Guide](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.optimize.linear_sum_assignment.html)

## (3) Loss

[detr/detr.py at main · facebookresearch/detr](https://github.com/facebookresearch/detr/blob/main/models/detr.py)

```python
class SetCriterion(nn.Module):
    """ This class computes the loss for DETR.
    The process happens in two steps:
        1) we compute hungarian assignment between ground truth boxes and the outputs of the model
        2) we supervise each pair of matched ground-truth / prediction (supervise class and box)
    """
    def __init__(self, num_classes, matcher, weight_dict, eos_coef, losses):
        """ Create the criterion.
        Parameters:
            num_classes: number of object categories, omitting the special no-object category
            matcher: module able to compute a matching between targets and proposals
            weight_dict: dict containing as key the names of the losses and as values their relative weight.
            eos_coef: relative classification weight applied to the no-object category
            losses: list of all the losses to be applied. See get_loss for list of available losses.
        """
        super().__init__()
        self.num_classes = num_classes
        self.matcher = matcher
        self.weight_dict = weight_dict
        self.eos_coef = eos_coef
        self.losses = losses
        empty_weight = torch.ones(self.num_classes + 1)
        empty_weight[-1] = self.eos_coef
        self.register_buffer('empty_weight', empty_weight)

    def loss_labels(self, outputs, targets, indices, num_boxes, log=True):
        """Classification loss (NLL)
        targets dicts must contain the key "labels" containing a tensor of dim [nb_target_boxes]
        """
        assert 'pred_logits' in outputs
        src_logits = outputs['pred_logits']

        idx = self._get_src_permutation_idx(indices)
        target_classes_o = torch.cat([t["labels"][J] for t, (_, J) in zip(targets, indices)])
        target_classes = torch.full(src_logits.shape[:2], self.num_classes,
                                    dtype=torch.int64, device=src_logits.device)
        target_classes[idx] = target_classes_o

        loss_ce = F.cross_entropy(src_logits.transpose(1, 2), target_classes, self.empty_weight)
        losses = {'loss_ce': loss_ce}

        if log:
            # TODO this should probably be a separate loss, not hacked in this one here
            losses['class_error'] = 100 - accuracy(src_logits[idx], target_classes_o)[0]
        return losses

    @torch.no_grad()
    def loss_cardinality(self, outputs, targets, indices, num_boxes):
        """ Compute the cardinality error, ie the absolute error in the number of predicted non-empty boxes
        This is not really a loss, it is intended for logging purposes only. It doesn't propagate gradients
        """
        pred_logits = outputs['pred_logits']
        device = pred_logits.device
        tgt_lengths = torch.as_tensor([len(v["labels"]) for v in targets], device=device)
        # Count the number of predictions that are NOT "no-object" (which is the last class)
        card_pred = (pred_logits.argmax(-1) != pred_logits.shape[-1] - 1).sum(1)
        card_err = F.l1_loss(card_pred.float(), tgt_lengths.float())
        losses = {'cardinality_error': card_err}
        return losses

    def loss_boxes(self, outputs, targets, indices, num_boxes):
        """Compute the losses related to the bounding boxes, the L1 regression loss and the GIoU loss
           targets dicts must contain the key "boxes" containing a tensor of dim [nb_target_boxes, 4]
           The target boxes are expected in format (center_x, center_y, w, h), normalized by the image size.
        """
        assert 'pred_boxes' in outputs
        idx = self._get_src_permutation_idx(indices)
        src_boxes = outputs['pred_boxes'][idx]
        target_boxes = torch.cat([t['boxes'][i] for t, (_, i) in zip(targets, indices)], dim=0)

        loss_bbox = F.l1_loss(src_boxes, target_boxes, reduction='none')

        losses = {}
        losses['loss_bbox'] = loss_bbox.sum() / num_boxes

        loss_giou = 1 - torch.diag(box_ops.generalized_box_iou(
            box_ops.box_cxcywh_to_xyxy(src_boxes),
            box_ops.box_cxcywh_to_xyxy(target_boxes)))
        losses['loss_giou'] = loss_giou.sum() / num_boxes
        return losses

    
    def _get_src_permutation_idx(self, indices):
        # permute predictions following indices
        batch_idx = torch.cat([torch.full_like(src, i) for i, (src, _) in enumerate(indices)])
        src_idx = torch.cat([src for (src, _) in indices])
        return batch_idx, src_idx

    def _get_tgt_permutation_idx(self, indices):
        # permute targets following indices
        batch_idx = torch.cat([torch.full_like(tgt, i) for i, (_, tgt) in enumerate(indices)])
        tgt_idx = torch.cat([tgt for (_, tgt) in indices])
        return batch_idx, tgt_idx

    def get_loss(self, loss, outputs, targets, indices, num_boxes, **kwargs):
        loss_map = {
            'labels': self.loss_labels,
            'cardinality': self.loss_cardinality,
            'boxes': self.loss_boxes,
            'masks': self.loss_masks
        }
        assert loss in loss_map, f'do you really want to compute {loss} loss?'
        return loss_map[loss](outputs, targets, indices, num_boxes, **kwargs)

    def forward(self, outputs, targets):
        """ This performs the loss computation.
        Parameters:
             outputs: dict of tensors, see the output specification of the model for the format
             targets: list of dicts, such that len(targets) == batch_size.
                      The expected keys in each dict depends on the losses applied, see each loss' doc
        """
        outputs_without_aux = {k: v for k, v in outputs.items() if k != 'aux_outputs'}

        # Retrieve the matching between the outputs of the last layer and the targets
        indices = self.matcher(outputs_without_aux, targets)

        # Compute the average number of target boxes accross all nodes, for normalization purposes
        num_boxes = sum(len(t["labels"]) for t in targets)
        num_boxes = torch.as_tensor([num_boxes], dtype=torch.float, device=next(iter(outputs.values())).device)
        if is_dist_avail_and_initialized():
            torch.distributed.all_reduce(num_boxes)
        num_boxes = torch.clamp(num_boxes / get_world_size(), min=1).item()

        # Compute all the requested losses
        losses = {}
        for loss in self.losses:
            losses.update(self.get_loss(loss, outputs, targets, indices, num_boxes))

        # In case of auxiliary losses, we repeat this process with the output of each intermediate layer.
        if 'aux_outputs' in outputs:
            for i, aux_outputs in enumerate(outputs['aux_outputs']):
                indices = self.matcher(aux_outputs, targets)
                for loss in self.losses:
                    if loss == 'masks':
                        # Intermediate masks losses are too costly to compute, we ignore them.
                        continue
                    kwargs = {}
                    if loss == 'labels':
                        # Logging is enabled only for the last layer
                        kwargs = {'log': False}
                    l_dict = self.get_loss(loss, aux_outputs, targets, indices, num_boxes, **kwargs)
                    l_dict = {k + f'_{i}': v for k, v in l_dict.items()}
                    losses.update(l_dict)

        return losses
```

여기서는 loss를 구성하는 항목을 dict에 기록했다가 전체 loss는 main.py에서 dict에 있는 정보를 engine.py에 있는 train_one_epoch 함수에 전달하여 backpropagation을 하게 된다.

논문 상에서 정의된 loss는 negative log likelihood인 classification loss와 위에서 matching cost를 구하기 위해 사용했던 box loss로 구성된다.

$\mathcal{L}_{Hungarian}(y,\hat{y})=\sum_{i=1}^N[-log\ \hat{p}_{\hat{\sigma}(i)}(c_i)+\mathbb{1}_{\{c_i\neq \varnothing\}}\mathcal{L}_{box}(b_i,\hat{b}_{\hat{\sigma}(i)})]$

Classification loss인 $-log\ \hat{p}_{\sigma(i)}(c_i)$는 softmax의 negative log likelihood인 cross entropy 값으로 `loss_labels` 함수에 있는 `loss_ce`이다. 

그리고 Bounding box의 loss를 `loss_boxes` 함수에서 구하는데, 리턴은 L1 loss인 `losses['loss_bbox']`와 gIoU인 `losses['loss_giou']`를 따로 한다.

논문에는 나오지 않지만 예측된 Bounding box 중에서 Classification이 No-object가 아닌 것들의 L1 loss를 Cardinality error라고 정의해서 구해주지만 `loss_cardinality` 함수 위에 데코레이터 `torch.no_grad()`를 붙여줌으로써 gradient descent optimization 과정에서는 빠진다. 즉 학습과정 중에 참고용 metric일 뿐 Cardinality loss가 학습에 반영되는 것은 아니다.

그리고 `loss_masks`로 구하는 loss는 4.4 Panoptic segmentation에 적용할 때 Mask head를 추가해서 예측된 Bounding box에 대한 binary mask를 구한다는 항목을 보았을 것이다. Mask head를 지도학습하기 위한 DICE loss와 Focal loss를 구하는 것이다.

> We also add a mask head which predicts a binary mask for each of the predicted boxes, see Figure 8. It takes as input the output of transformer decoder for each object and computes multi-head (with $M$ heads) attention scores of this embedding over the output of the encoder, generating $M$ attention heatmaps per object in a small resolution. To make the final prediction and increase the resolution, an FPN-like architecture is used. We describe the architecture in more details in the supplement. The final resolution of the masks has stride 4 and each mask is supervised independently using the DICE/F-1 loss [28] and Focal loss [23].
> 

[detr/engine.py at main · facebookresearch/detr](https://github.com/facebookresearch/detr/blob/main/engine.py)

```python
def train_one_epoch(model: torch.nn.Module, criterion: torch.nn.Module,
                    data_loader: Iterable, optimizer: torch.optim.Optimizer,
                    device: torch.device, epoch: int, max_norm: float = 0):
    model.train()
    criterion.train()
    metric_logger = utils.MetricLogger(delimiter="  ")
    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))
    metric_logger.add_meter('class_error', utils.SmoothedValue(window_size=1, fmt='{value:.2f}'))
    header = 'Epoch: [{}]'.format(epoch)
    print_freq = 10

    for samples, targets in metric_logger.log_every(data_loader, print_freq, header):
        samples = samples.to(device)
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]

        outputs = model(samples)
        loss_dict = criterion(outputs, targets)
        weight_dict = criterion.weight_dict
        losses = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)

        # reduce losses over all GPUs for logging purposes
        loss_dict_reduced = utils.reduce_dict(loss_dict)
        loss_dict_reduced_unscaled = {f'{k}_unscaled': v
                                      for k, v in loss_dict_reduced.items()}
        loss_dict_reduced_scaled = {k: v * weight_dict[k]
                                    for k, v in loss_dict_reduced.items() if k in weight_dict}
        losses_reduced_scaled = sum(loss_dict_reduced_scaled.values())

        loss_value = losses_reduced_scaled.item()

        if not math.isfinite(loss_value):
            print("Loss is {}, stopping training".format(loss_value))
            print(loss_dict_reduced)
            sys.exit(1)

        optimizer.zero_grad()
        losses.backward()
        if max_norm > 0:
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)
        optimizer.step()

        metric_logger.update(loss=loss_value, **loss_dict_reduced_scaled, **loss_dict_reduced_unscaled)
        metric_logger.update(class_error=loss_dict_reduced['class_error'])
        metric_logger.update(lr=optimizer.param_groups[0]["lr"])
    # gather the stats from all processes
    metric_logger.synchronize_between_processes()
    print("Averaged stats:", metric_logger)
    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}
```

## (4) Augmentation

논문의 4 Experiments의 Technical details에 나와 있듯이, Input image는 Resizing을 거친다.

> We use scale augmentation, resizing the input images such that the shortest side is at least 480 and at most 800 pixels while the longest at most 1333 [50]. To help learning global relationships through the self-attention of the encoder, we also apply random crop augmentations during training, improving the performance by approximately 1 AP. Specifically, a train image is cropped with probability 0.5 to a random rectangular patch which is then resized again to 800-1333.
> 

Train을 하기 전에는 Scale Augmentation을 하는데 이미지의 Width, Height 중 짧은 쪽을 최소 480 픽셀, 최대 1333 픽셀의 범위에서 맞춰주며, 그 중 800 픽셀이 가장 많이 선택되도록 유도한다.  Random하게 선택된 이미지를 Crop 해서 그 이미지를 다시 Resizing 해주는 방식의 Augmentation도 들어간다.

[detr/coco.py at main · facebookresearch/detr](https://github.com/facebookresearch/detr/blob/main/datasets/coco.py)

```python
def make_coco_transforms(image_set):

    normalize = T.Compose([
        T.ToTensor(),
        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    scales = [480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800]

    if image_set == 'train':
        return T.Compose([
            T.RandomHorizontalFlip(),
            T.RandomSelect(
                T.RandomResize(scales, max_size=1333),
                T.Compose([
                    T.RandomResize([400, 500, 600]),
                    T.RandomSizeCrop(384, 600),
                    T.RandomResize(scales, max_size=1333),
                ])
            ),
            normalize,
        ])

    if image_set == 'val':
        return T.Compose([
            T.RandomResize([800], max_size=1333),
            normalize,
        ])

    raise ValueError(f'unknown {image_set}')
```

# 3 Discussion

## (1) GT class가 'No object'일 때($c_i=\varnothing$) 클래스 예측 확률 $\hat{p}_{\sigma(i)}(c_i)$을 Matching Cost에 반영하지 않는 이유

Matching Cost의 식은 다음과 같다.

$\mathcal{L}_{match}(y_i,\hat{y}_{\sigma(i)})=-\mathbb{1}_{\{c_i\neq \varnothing\}}\hat{p}_{\sigma(i)}(c_i)+\mathbb{1}_{\{c_i\neq \varnothing\}}\mathcal{L}_{box}(b_i,\hat{b}_{\sigma(i)})$

우선 GT가 No object라면 Bounding Box의 의미가 없다. GT Bounding Box가 없기 때문에 gIoU 계산 자체가 성립되지 않는다. 따라서 Box loss 쪽을 계산하지 않는 것은 납득이 된다.

그렇다면 class의 확률, 그 중에서도 DETR이 No object일 확률을 계산했을 경우는 어떨까
![cost_matrix1](/assets/img_cv/DETR_cost_matrix1.png)
우선 모든 GT와 Prediction이 위와 같은 비용행렬을 갖는다고 생각해보자. Row index는 GT, Column index는 Prediction이다.

Hungarian Algorithm을 거치면, 아래처럼 일대일대응으로 매칭될 것이다.  
![cost_matrix2](/assets/img_cv/DETR_cost_matrix2.png)
만약에

GT의 두번째 인덱스의 class가 No object라면 어떨까  
![cost_matrix3](/assets/img_cv/DETR_cost_matrix3.png)
일단 BBox cost는 계산할 수 없다. GT BBox가 없으니까

그럼 $i=2$일 때, Cost는 class probability의 Negative value(음수)가 될 것이다.  
![cost_matrix4](/assets/img_cv/DETR_cost_matrix4.png)
Softmax 값이므로 합치면 -1이 될 것이다. 

위의 Hungarian Algorithm을 적용하는 블로그를 보면 알겠지만, 이런 식으로 값을 남겨 놓으면, Matching을 찾을 때 영향을 주게 되어 있다. 

그럴바에야 그냥 No object인 경우는 아예 제외하고 Hungarian Algorithm을 적용하면  
![cost_matrix5](/assets/img_cv/DETR_cost_matrix5.png)
Matching이 구해질 것이고, Matching되지 않은 Prediction은 그냥 No object로 Matching 해버리는 것이다.

소스코드의 주석을 보면

```python
class HungarianMatcher(nn.Module):
    """This class computes an assignment between the targets and the predictions of the network
    For efficiency reasons, the targets don't include the no_object. Because of this, in general,
    there are more predictions than targets. In this case, we do a 1-to-1 matching of the best predictions,
    while the others are un-matched (and thus treated as non-objects).
    """
```

Efficiency 때문에 GT에 no_object를 포함시키지 않았다고 한다!!!. 그냥 노빠구로 Matching 시키고 남는 prediction은 그냥 no_object로 처리한다고 한다.

논문의 Figure 1의 캡션을 봐도 마찬가지

<p align = "center">
<img src="/assets/img_cv/DETR_figure1.png" alt="DETR figure1" width="550" />
</p>
<p>
Fig. 1: DETR directly predicts (in parallel) the final set of detections by combining a common CNN with a transformer architecture. During training, bipartite matching uniquely assigns predictions with ground truth boxes. Prediction with no match should yield a `"no object"` ($\varnothing$) class prediction.
</p>


결론: Matching 자체를 $c_i\neq \varnothing$ 에서 하기 때문에 Matching Cost에 $c_i = \varnothing$의 경우는 포함되면 안되는 것이다.

## (2) NMS와 Anchor generation 안하는 게 좋은가?

초록에서 서술한바와 같이 DETR은 NMS와 Anchor generation할 필요가 없다.

> Our approach streamlines the detection pipeline, effectively removing the need for many hand-designed components like a non-maximum suppression procedure or anchor generation that explicitly encode our prior knowledge about the task.
> 

근데 그게 더 좋은가? 더 빠른가?

먼저 사람이 prior knowledge를 가지고 지정해줘야 할 부분은

NMS의 경우 제거할 박스의 IoU Threshold와 Anchor Generation 할 때 k-means clustering(YOLOv2)의 k 값

DETR의 경우 Matching과 Loss를 구할 때 들어가는 Box loss 계산에서 gIoU와 L1 loss의 선형결합 가중치, Output prediction의 갯수 N

두번째로 DETR 모델이 파이프라인 간소화를 할 때 더 빨라지는가 이다.

결론은 

그렇지 않다.  
![table1](/assets/img_cv/DETR_table1.png)  
Table 1에서 Faster RCNN하고 비교한 결과를 보면, 모델 자체는 DETR이 더 가벼움에도 불구하고, FPS는 오히려 낮았다. 논문에서는 Faster RCNN과 비등하다고 포장했지만, 사실 YOLO 까지 갈 필요도 없이, Faster RCNN 선에서 정리된다.

GPU 16개로 COCO dataset 300 epoch 학습시키는데 3일이 걸렸다는 점은 DETR이 느리고 자원을 많이 사용한다는 반증이 된다.

실제로 서버의 자원 사용 현황을 보면
![resource](/assets/img_cv/DETR_resource.png)
하늘색 사각형이 KorBERT를 학습시킨 기간, 보라색 사각형이 DETR을 학습시킨 기간인데 DETR의 CPU와 Memory 사용량이 상당함을 알 수 있다.

이는 Hungarian Algorithm을 해야되기 때문으로 보이며, Hungarian Algorithm은 Inference 할 때도 적용해야 하기 때문에 Inference 속도와 자원할당에 문제가 될 수 있다.

